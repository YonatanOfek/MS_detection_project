import numpy as npimport matplotlib.pyplot as pltimport cv2 as cvimport osdef ReLU(x):    return abs(x)*(x > 0)def sigmoid(x):    return 1.0 / (1.0 + np.exp(-x))def sigmoid_derivative(x):    return 1.0 / (2.0 + np.exp(-2.0 * x) + 2.0 * np.exp(-x))  # ??def relu_derivative(x):    return 1.0 * (x > 0)  # ??def calculate_accuracy(prob, label):    return prob - label  # ??def calculate_accuracy_mean(accuracy, batch_size):    return accuracy / batch_size  # ??def calculate_loss(loss, batch_size):    return loss / batch_size  # ??class TrainingExperiment:    pass    # def __init__(self, net: NeuralNet, number_of_epochs, size_of_batches, input_vector, label_vector):    #     self.NN = net    #     pass    # def epoch(self):    #class NeuralNet:    def __init__(self, nn_hidden_layer_dimension, nn_input_dim=1024):        nn_output_dim = 1        np.random.seed(0)        w1 = np.random.randn(nn_input_dim, nn_hidden_layer_dimension) / np.sqrt(nn_input_dim)        b1 = np.zeros((1, nn_hidden_layer_dimension))        w2 = np.random.randn(nn_hidden_layer_dimension, nn_output_dim) / np.sqrt(nn_hidden_layer_dimension)        b2 = np.zeros((1, nn_output_dim))        self.weights = [w1, w2]        self.biases = [b1, b2]    def back_propagation(self, image, label):        # create input vector        curr_input = image        curr_input = np.ravel(curr_input).reshape((1, 1024))        # Forward propagation        # Edges inputting into the hidden layer        z1 = curr_input.dot(self.weights[0]) + self.biases[0]        a1 = ReLU(z1)        # Edges outputting from the hidden layer, into the output layer        z2 = a1.dot(self.weights[1]) + self.biases[1]        prob_bp = sigmoid(z2)        # Back propagation        delta3 = (prob_bp[0][0] - label) * sigmoid_derivative(z2)        delta2 = delta3.dot(self.weights[1].T) * relu_derivative(z1)        dw2 = a1.T.dot(delta3)        dw1 = curr_input.T.dot(delta2)        d_nabla_b = [delta2, delta3]        d_nabla_w = [dw1, dw2]        return d_nabla_b, d_nabla_w, prob_bp    def update_batch(self, batch, lr, batch_size):        nabla_w = [np.zeros(w.shape) for w in self.weights]        nabla_b = [np.zeros(b.shape) for b in self.biases]        loss = []        accuracy = []        for image, label in batch:            db, dw, prob = self.back_propagation(image, label)            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, dw)]            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, db)]            loss.append(((label - prob) ** 2) / 2)            accuracy.append(calculate_accuracy(prob[0][0], label))        # update rule        self.weights = [w - (lr / batch_size) * dw for w, dw in zip(self.weights, nabla_w)]        self.biases = [b - (lr / batch_size) * db for b, db in zip(self.biases, nabla_b)]        mean_loss = calculate_loss(loss, batch_size)        mean_accuracy = calculate_accuracy_mean(accuracy, batch_size)        return mean_loss, mean_accuracyif __name__ == '__main__':    net1 = NeuralNet(1)    training_pictures = []    labels = []    m_loss = np.zeros(30)    m_accuracy = np.zeros(30)    directory_string = 'C://Users/User/PycharmProjects/MSDetectionProject/MS_Dataset_2019/training'    directory = os.fsencode(directory_string)    for picture in os.listdir(directory):        filename = os.fsdecode(picture)        if filename.endswith(".png") or filename.endswith(".jpg"):            current_image = cv.imread(os.path.join(directory_string, filename), 0)            training_pictures.append(current_image)            if filename.startswith("neg"):                labels.append(0)            elif filename.startswith("pos"):                labels.append(1)  # todo: add exceptions            continue        else:            continue    data = zip(training_pictures, labels)    for i in range(30):        m_loss[i], m_accuracy[i] = net1.update_batch(data, 1, len(training_pictures))    plt.figure()    plt.plot(m_accuracy)    plt.figure()    plt.plot(m_loss)